---
title: "Esame_Scritto_27/04/2020"
author: "Luca Testa 816000"
date: "27/4/2020"
output:
  word_document: default
  pdf_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r}
library(readr)
library(car)
library(sjstats)
library(plotrix)
library(sjPlot)
library(sjmisc)
library(lme4)
library(pander)
library(car)
library(olsrr)
library(systemfit)
library(het.test)
library(ppcor)
library(snakecase)
library(performance)
library(glmmTMB)

panderOptions('knitr.auto.asis', FALSE)

#-- White test function
white.test <- function(lmod,data=d){
  u2 <- lmod$residuals^2
  y <- fitted(lmod)
  Ru2 <- summary(lm(u2 ~ y + I(y^2)))$r.squared
  LM <- nrow(data)*Ru2
  p.value <- 1-pchisq(LM, 2)
  data.frame("Test statistic"=LM,"P value"=p.value)
}

# funzione per ottenere osservazioni outlier univariate
FIND_EXTREME_OBSERVARION <- function(x,sd_factor=2){
  which(x>mean(x)+sd_factor*sd(x) | x<mean(x)-sd_factor*sd(x))
}

# import del dataset
d <- read_delim("C:/Users/lucat/Desktop/PISA_USA.csv", 
    ";", escape_double = FALSE, trim_ws = TRUE)

# vista delle prima 6 righe del dataset
head(d)

# controllo tipo di ogni colonna del dataset
str(d)

```

```{r}
#-- vettore di variabili numeriche presenti nei dati per attuare statistiche descrittive
VAR_NUMERIC <- c("JOYREAD","SOCIO_ECONOMIC_STATUS","AGE","SCHOOL_SELECTIVITY")

#-- STATISTICHE DESCRITTIVE

# Si propongono la matrice di correlazione tra le variabili e alcune descrittive di base.

# Qui posso notare come le variabili sembrano essere tutte quasi simmetriche
summary(d[,VAR_NUMERIC])

# Non sembrano esserci correlazioni di nessun tipo, tutti i valori sono molto bassi
# Niente fa presagire che ci siano delle variabili collineari tra di loro, ovvero che
# due o piÃ¹ varibili siano correlate tra di loro andando a formare una matrice X'X singolare
# La cosa, appunto, Ã¨ esclusa
cor(d[,VAR_NUMERIC])

# Le variabili sembrano essere tutte molto vicine alla simmetria, soltanto le prime due hanno una coda
# piÃ¹ pesante a destra e a sinistra e segnalano la presenza di outlier
par(mfrow=c(2,2))
for(i in VAR_NUMERIC){
  boxplot(d[,i],main=i,col="lightblue",ylab=i)
}


```

```{r}
# REGRESSIONE
# Si utilizzano come variabili esplicative rispetto a JOYREAD: SOCIO_ECONOMIC_STATUS + AGE + SCHOOL_SELECTIVITY.

#-- R CODE
# Stima modello lineare semplice
mod1 <- lm(JOYREAD ~ SOCIO_ECONOMIC_STATUS + AGE + SCHOOL_SELECTIVITY, d) 

# L'unica variabile che sembra essere significativa per questo modello Ã¨ "SOCIO_ECONOMIC_STATUS".
# Il modello ha un fitting veramente basso, quasi insignificante anche se, il p-value mostra che il modello
# viene spiegato bene, si prosegue nei vari test.
summary(mod1)

# Il primo plot sembra segnalare una leggera eteroschedasticitÃ  dovuta alla non completa ottima distribuzione
# dei residui. Il secondo grafico segnala che siamo in presenza di non normalitÃ . Il terzo grafico segnala un paio di outlier non del tutti perÃ² significativi, verrÃ  approfondita la questione tramite test ad hoc. Anche il quarto grafico sembra segnalare la presenza di leverage poco significativi.
plot(mod1,pch=19)

# Varianza multifattoriale o Vif(x_j)=1/Tol(x_j)=1/(1-R2(x_j/x_1,â€¦, x_(j-1), x_(j+1),â€¦, x_p)), ovvero il reciproco della tolleranza. Valori di tale indice variano tra 0 e 1 perciÃ² se superiori a 20 indicano uno stretto rapporto tra la variabile considerata e le altre ovvero un eccessivo grado di multicollinearitÃ . Anche oltre 10 andrebbero controllate
# In questo modello non ne viene perÃ² segnalata la presenza.
ols_vif_tol(mod1)

# Questo test si basa sullâ€™assunzione di omoschedasticitÃ   dei residui, viene perciÃ² definita lâ€™ipotesi nulla come H0 : # Var(ei) = (o2) e lâ€™ipotesi alternativa come H1 : Var(ei) = ( oi2). Il test sfrutta la regressione OLS del quadrato dei # residui ei2 sui regressori xj, i regressori al quadrato xj2e le loro interazioni. 
# Con un valore pari a 0.08 possiamo dire di avere una leggera eteroschedasticitÃ  da migliorare tramite una stima WLS, per essere sicuri dell'omoschedasticitÃ , come segnalato durante le lezioni, il valore dev'essere superiore o uguale a 0.1.
white.test(mod1)

# Lâ€™ipotesi nulla Ã¨: H_0:Ï=Corr[Îµ_i^#, Îµ_(i-1)^#]=0
# Con valori della statistica compresi tra 1 e 3 si puÃ² dire di avere incorrelazione.
# Nel caso di autocorrelazione, il teorema di Aitken stabilisce che nella classe degli stimatori lineari per il modello # di regressione generalizzato lo stimatore GLS Ã¨ efficiente in quanto caratterizzato dalla minima varianza.
# Il valore di 1.9486 ci segnala la presenza di incorrelazione tra i residui.
dwtest(mod1)

# I test seguenti sono stati fatti per vedere la quantitÃ  di outlier presenti all'interno del modello.
# I grafici sottolineano un'elevata presenza di outlier.
# Residui studentizzati: Ã¨ la versione dei residui standardizzati ma relativamente al campione. Di conseguenza le forme analitiche saranno le medesime facendo perÃ² riferimento non alla varianza o2 ma alla varianza campionaria s2.
{plot(fitted(mod1),rstudent(mod1), pch=19, xlab="Predicted", ylab="Student - Residual")
abline(h=-2,col=2,lty=2,lwd=2)
abline(h=2,col=2,lty=2,lwd=2)}

# Misura lâ€™influenza dellâ€™i-esima osservazione sulla stima dei coefficienti di regressione nel loro complesso, in termini di capacitÃ  del modello di predire tutti i casi quando la singola osservazione viene rimossa dal dataset. Valori superiori a 1 (o eventualmente a 4/n, essendo n il numero di osservazioni) indicano che il punto Ã¨ influente.
{plot(cooks.distance(mod1), pch=19, xlab="Observation Index", ylab="Cook DIstance", type="h")
points(cooks.distance(mod1), pch=19)
abline(h=4/nrow(d), col=2, lty=2, lwd=2)}

influenceIndexPlot(mod1)


```

```{r}
# REGRESSIONE MULTILEVEL: Empty Model

# Modello ANOVA ad effetti casuali (empty model)
# Modello
mod2 <- lmer(JOYREAD ~ (1 | SCHOOLID), d, REML=T)
summary(mod2)

mod1_null <- lm(JOYREAD ~ 1, d)
anova(mod2, mod1_null)

performance::icc(mod2)

res <- plot_model(mod2, type = "re", grid = FALSE, show.values=T,title="T",prnt.plot=F, sort.est ="sort.all" )
data_1 =res$data[order(res$data$estimate),]
{plotCI(1:nrow(data_1),data_1$estimate,ui=data_1$conf.high, li=data_1$conf.low ,pch=19,scol="blue",xlab="School",ylab="Estimate")
abline(h=mean(data_1$estimate),col=2,lwd=3,lty=2)}

# E' respinta l'ipotesi che il modello non interpreti i dati e dal rapporto tra varianza spiegata e totale si ricava
# un coefficiente intraclasse pari a 0.03 che Ã¨ molto basso, e segnala una bassa variabilitÃ  fra le scuole nei punteggi
# di JOYREAD. Si propongono poi i valori attesi e gli intervalli di confidenza dei parametri casuali inerenti le
# singole scuole. Per i parametri casuali il modello postula graduatorie basate su valori attesi e intervalli di
# confidenza.
# Come Ã¨ noto una scuola A puÃ² ritenersi superiore a una scuola B in termini di efficacia solo se l'estremo
# inferiore dell'intervallo di confidenza di A sia superiore all'estremo superiore dell'intervallo di confidenza di B.
# Dal grafico posso anche affermare che ci sono poche scuole significativamente diverse da 0, cioÃ¨ che, non hanno nel loro intervallo di confidenza appunto lo 0.

# Modello ANOVA ad effetti casuali detto anche empty model: yij=ð›Œ00+vj+Îµij; Îµij âˆ¼ N(0, Ïƒ2); vj âˆ¼ N(0, Ï„2 )
# In questo caso la variabile dipendente y dipende dagli effetti casuali:
# 1) a livello di gruppo, Vj, distribuiti in modo normale N(ð›Œ00; Ï„2)
# 2) a livello individuale, dai residui Rij, distribuiti in modo normale N(0; Ïƒ2)


```

```{r}
# REGRESSIONE MULTILEVEL: Random Intercept
# MOdello empty al quale si inserisce una variabile esplicativa  (random  intercept model -  mixed model) 
# Multilevel perchÃ¨ tiene conto sia della parte di regressione che di analisi della varianza ed Ã¨ la sintesi dei modelli empty e OLS

#-- R CODE
mod3 <- lmer(JOYREAD ~ SOCIO_ECONOMIC_STATUS + (1 | SCHOOLID), d, REML=T)
summary(mod3)

Anova(mod3, type="III")

performance::icc(mod3)

res <- plot_model(mod3, type = "re", grid = FALSE, show.values=T,title="T",prnt.plot=F, sort.est ="sort.all" )
data_1 =res$data[order(res$data$estimate),]
{plotCI(1:nrow(data_1),data_1$estimate,ui=data_1$conf.high, li=data_1$conf.low ,pch=19,scol="blue",xlab="School",ylab="Estimate")
abline(h=mean(data_1$estimate),col=2,lwd=3,lty=2)}

# Il coefficiente di correlazione intraclasse si abbassa di pochissimo (0.027), rimanendo veramente basso, in quanto si abbassano in uguale proporzione varianza spiegata e residua. Il modello interpreta bene i dati e la variabile SOCIO_ECONOMIC_STATUS risulta significativa. Anche il test di 3Â° tipo degli effetti fissi conferma questa significativitÃ . Si propongono i valori attesi e gli intervalli di confidenza dei parametri casuali inerenti i gruppi. Si vede come il ranking non muti in modo rilevante al caso empty. CiÃ² mostra che la diversa distribuzione fra le scuole della variabile SOCIO_ECONOMIC_STATUS non Ã¨ all'origine di parte della variabilitÃ  di "JOYREAD" attribuito in prima istanza nel modello empty alla efficacia delle scuole.

# yij = ð›Œ 00 +Î²1xij+ vj+ Îµij; Îµij âˆ¼ N(0, Ïƒ2);             
# Dove vj Ã¨ la determinazione della variabile casuale Vj distribuita normalmente N(ð›Œ00; Ï„2) a rappresentazione dei residui di secondo livello. Essi sono indipendenti e quindi incorrelati con i residui di primo livello Îµij determinazioni della variabile casuale normalmente distribuita Eij ~ N(0; Ïƒ2)

```

```{r}
# 2Â° REGRESSIONE MULTILEVEL

mod4 <- lmer(JOYREAD ~ SOCIO_ECONOMIC_STATUS + AGE + (1 | SCHOOLID), d, REML=T)
summary(mod4)

Anova(mod4, type="III")

performance::icc(mod4)

res <- plot_model(mod4, type = "re", grid = FALSE, show.values=T,title="T",prnt.plot=F, sort.est ="sort.all" )
data_1 =res$data[order(res$data$estimate),]
{plotCI(1:nrow(data_1),data_1$estimate,ui=data_1$conf.high, li=data_1$conf.low ,pch=19,scol="blue",xlab="School",ylab="Estimate")
abline(h=mean(data_1$estimate),col=2,lwd=3,lty=2)}

# Il coefficiente di correlazione intraclasse si abbassa di pochissimo ancora (0.026). Il modello interpreta bene i dati e la variabile SOCIO_ECONOMIC_STATUS risulta significativa mentre la variabile AGE no con un valore di Chisq veramente basso, questo vuol dire che non "ruba" parte della variabilitÃ . Si propongono i valori attesi e gli intervalli di confidenza dei parametri casuali inerenti i gruppi. Si vede come il ranking non muti in modo rilevante, anzi, peggiori.

```


```{r}
# 3Â° REGRESSIONE MULTILEVEL
# 2 variabili di primo livello e 1 variabile di secondo 2 livello

#-- RIMUOVO L'OUTLIER -999
summary(d$STUDENT_TEACHER_RATIO)
d1 <- -d[!(d$STUDENT_TEACHER_RATIO == -999),]

mod5 <- lmer(JOYREAD ~ SOCIO_ECONOMIC_STATUS + AGE + STUDENT_TEACHER_RATIO + (1 | SCHOOLID), d1, REML=T)
summary(mod5)

Anova(mod5, type="III")

performance::icc(mod5)

res <- plot_model(mod5, type = "re", grid = FALSE, show.values=T,title="T",prnt.plot=F, sort.est ="sort.all" )
data_1 =res$data[order(res$data$estimate),]
{plotCI(1:nrow(data_1),data_1$estimate,ui=data_1$conf.high, li=data_1$conf.low ,pch=19,scol="blue",xlab="School",ylab="Estimate")
abline(h=mean(data_1$estimate),col=2,lwd=3,lty=2)}



# Il coefficiente di correlazione intraclasse rimane invariato (0.027), rimanendo veramente basso, in quanto si abbassano in uguale proporzione varianza spiegata e residua. Il modello interpreta bene i dati e la variabile SOCIO_ECONOMIC_STATUS risulta significativa, AGE no e nemmeno la variabile di secondo livello. Entrambe non catturano parte della variabilitÃ .Si propongono i valori attesi e gli intervalli di confidenza dei parametri casuali inerenti i gruppi. Si vede come il ranking non muti in modo rilevante e come non sia possibile comunque stilare un ranking.
```


```{r}
# REGRESSIONE MULTILEVEL: Random Slope
# Questo modello prevede che i coefficienti della regressione varino da gruppo a gruppo 

mod6 <- lmer(JOYREAD ~ 1 + (SOCIO_ECONOMIC_STATUS| SCHOOLID), d, REML=T)
summary(mod6)

Anova(mod6, type="III")


res <- plot_model(mod6, type = "re", grid = FALSE, show.values=T,title="T",prnt.plot=F, sort.est ="sort.all" )


data_coef = res[[1]]$data[order(res[[1]]$data$estimate),]
data_int  = res[[2]]$data[order(res[[2]]$data$estimate),]


{plotCI(1:nrow(data_coef),data_coef$estimate,ui=data_coef$conf.high, li=data_coef$conf.low ,pch=19,scol="blue",xlab="Group1",ylab="Estimate")
abline(h=mean(data_coef$estimate),col=2,lwd=3,lty=2)}

{plotCI(1:nrow(data_int),data_int$estimate,ui=data_int$conf.high, li=data_int$conf.low ,pch=19,scol="red",xlab="Group2",ylab="Estimate")
abline(h=mean(data_int$estimate),col=2,lwd=3,lty=2)}

# Il coefficiente intraclasse non puÃ² piÃ¹ essere calcolato nel modo semplice precedente perchÃ© si deve tener
# conto della correlazione tra effetti casuali relativi a "JOYREAD" e alle scuole nel loro complesso. Gli effetti
# casuali complessivi relativi all'efficacia delle scuole nel loro complesso e "JOYREAD" sono significativi. La correlazione tra effetti relativi alle scuole e a "JOYREAD" Ã¨ leggermente positiva.
# Sia per il coefficiente che per l'intercetta non possiamo stilare un ranking vero e proprio in quanto non siamo in presenza di differenza significativamente diverse fra le scuole.
# Sono poche quelle (come la 157) ad essere significativamente diverse da 0.

# Dato il modello random intercept si puÃ² proporre il modello random slope (total effects): yij=ð›Œ00+Î²1j* xij +vj+Îµij=yij=ð›Œ00+(Î²1j 0+Î²1j)xij+vj+Îµij ove i coefficiente Î²1j  (j=1,â€¦,p) variano da gruppo a gruppo poichÃ© lâ€™effetto di X su Y Ã¨ diverso nei diversi gruppi. 
# In questo caso non si Ã¨ in presenza di un total effects.
```





















